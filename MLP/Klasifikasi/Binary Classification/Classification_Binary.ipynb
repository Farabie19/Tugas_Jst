{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification_Binary.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_VjsESg7HwBb"},"source":["Binary Classification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6m8u1qGorfZv","executionInfo":{"status":"ok","timestamp":1621778180101,"user_tz":-420,"elapsed":17674,"user":{"displayName":"Farabie 19 Drive","photoUrl":"","userId":"03597380698045255649"}},"outputId":"42c92e5b-1bc0-4a8f-fa27-e8b8565698db"},"source":["#Mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ni3-vAvqIEqJ","executionInfo":{"status":"ok","timestamp":1621778184523,"user_tz":-420,"elapsed":2502,"user":{"displayName":"Farabie 19 Drive","photoUrl":"","userId":"03597380698045255649"}}},"source":["# Import Libaries\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nr8RyD7wIRzr","executionInfo":{"status":"ok","timestamp":1621778307933,"user_tz":-420,"elapsed":809,"user":{"displayName":"Farabie 19 Drive","photoUrl":"","userId":"03597380698045255649"}},"outputId":"edb0b360-6f9f-4d7f-eb97-0dc9924c6bbc"},"source":["#Load and Set the dataset\n","# load the dataset\n","path = '/content/drive/MyDrive/Tugas_Jst_2/MLP/Klasifikasi/Binary Classification/ionosphere.csv'\n","df = read_csv(path, header=None)\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","# ensure all data are floating point values\n","X = X.astype('float32')\n","# encode strings to integer\n","y = LabelEncoder().fit_transform(y)\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","# determine the number of input features\n","n_features = X_train.shape[1]"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(235, 34) (116, 34) (235,) (116,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wwfOPqnAIg07","executionInfo":{"status":"ok","timestamp":1621778316084,"user_tz":-420,"elapsed":4983,"user":{"displayName":"Farabie 19 Drive","photoUrl":"","userId":"03597380698045255649"}},"outputId":"72c70804-785f-4e1e-c488-7f37c9cc3a7b"},"source":["#Define, compile and fit model\n","# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(1, activation='sigmoid'))\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)\n","model.save(\"Binaryclassification.h5\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","8/8 [==============================] - 1s 2ms/step - loss: 1.1052 - accuracy: 0.3532\n","Epoch 2/150\n","8/8 [==============================] - 0s 2ms/step - loss: 1.0189 - accuracy: 0.3398\n","Epoch 3/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.9058 - accuracy: 0.3117\n","Epoch 4/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.8640 - accuracy: 0.2656\n","Epoch 5/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.7841 - accuracy: 0.3162\n","Epoch 6/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.7353 - accuracy: 0.4142\n","Epoch 7/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.4714\n","Epoch 8/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6137\n","Epoch 9/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.7483\n","Epoch 10/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.7945\n","Epoch 11/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.7827\n","Epoch 12/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7792\n","Epoch 13/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.8116\n","Epoch 14/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7730\n","Epoch 15/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7714\n","Epoch 16/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7605\n","Epoch 17/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7628\n","Epoch 18/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7852\n","Epoch 19/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7588\n","Epoch 20/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7754\n","Epoch 21/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7723\n","Epoch 22/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7899\n","Epoch 23/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8107\n","Epoch 24/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8016\n","Epoch 25/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.8372\n","Epoch 26/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7943\n","Epoch 27/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8028\n","Epoch 28/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8514\n","Epoch 29/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8338\n","Epoch 30/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8496\n","Epoch 31/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8464\n","Epoch 32/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8855\n","Epoch 33/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8784\n","Epoch 34/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8816\n","Epoch 35/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8710\n","Epoch 36/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.9038\n","Epoch 37/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8764\n","Epoch 38/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8781\n","Epoch 39/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8996\n","Epoch 40/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.9242\n","Epoch 41/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.9071\n","Epoch 42/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.3224 - accuracy: 0.9203\n","Epoch 43/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.9172\n","Epoch 44/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.9247\n","Epoch 45/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.9061\n","Epoch 46/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8867\n","Epoch 47/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.9014\n","Epoch 48/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.9222\n","Epoch 49/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.9022\n","Epoch 50/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.9197\n","Epoch 51/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.9098\n","Epoch 52/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.9160\n","Epoch 53/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9505\n","Epoch 54/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.9046\n","Epoch 55/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9528\n","Epoch 56/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9428\n","Epoch 57/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9318\n","Epoch 58/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9586\n","Epoch 59/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9266\n","Epoch 60/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9313\n","Epoch 61/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.8999\n","Epoch 62/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9493\n","Epoch 63/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9444\n","Epoch 64/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9248\n","Epoch 65/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9377\n","Epoch 66/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9404\n","Epoch 67/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9421\n","Epoch 68/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9454\n","Epoch 69/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9537\n","Epoch 70/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9291\n","Epoch 71/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9348\n","Epoch 72/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.9434\n","Epoch 73/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1644 - accuracy: 0.9415\n","Epoch 74/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9560\n","Epoch 75/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9601\n","Epoch 76/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9446\n","Epoch 77/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9488\n","Epoch 78/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9579\n","Epoch 79/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9670\n","Epoch 80/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9669\n","Epoch 81/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.9744\n","Epoch 82/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9570\n","Epoch 83/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.9730\n","Epoch 84/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9703\n","Epoch 85/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9646\n","Epoch 86/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.9680\n","Epoch 87/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9754\n","Epoch 88/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9665\n","Epoch 89/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9720\n","Epoch 90/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9696\n","Epoch 91/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9777\n","Epoch 92/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9777\n","Epoch 93/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9694\n","Epoch 94/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9788\n","Epoch 95/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9855\n","Epoch 96/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9724\n","Epoch 97/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9804\n","Epoch 98/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9817\n","Epoch 99/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9790\n","Epoch 100/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9839\n","Epoch 101/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9738\n","Epoch 102/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9773\n","Epoch 103/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9898\n","Epoch 104/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.9818\n","Epoch 105/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9757\n","Epoch 106/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9764\n","Epoch 107/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9761\n","Epoch 108/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9753\n","Epoch 109/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9831\n","Epoch 110/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9813\n","Epoch 111/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9858\n","Epoch 112/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9867\n","Epoch 113/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9799\n","Epoch 114/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9806\n","Epoch 115/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9923\n","Epoch 116/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.9858\n","Epoch 117/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9796\n","Epoch 118/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9745\n","Epoch 119/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9844\n","Epoch 120/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9739\n","Epoch 121/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9909\n","Epoch 122/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9799\n","Epoch 123/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9829\n","Epoch 124/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9877\n","Epoch 125/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9938\n","Epoch 126/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9943\n","Epoch 127/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9836\n","Epoch 128/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9886\n","Epoch 129/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9865\n","Epoch 130/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9754\n","Epoch 131/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9801\n","Epoch 132/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9806\n","Epoch 133/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9846\n","Epoch 134/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9898\n","Epoch 135/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9813\n","Epoch 136/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9830\n","Epoch 137/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9888\n","Epoch 138/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9870\n","Epoch 139/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9917\n","Epoch 140/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9958\n","Epoch 141/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9905\n","Epoch 142/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9950\n","Epoch 143/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9899\n","Epoch 144/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9865\n","Epoch 145/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9880\n","Epoch 146/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9888\n","Epoch 147/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9905\n","Epoch 148/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9905\n","Epoch 149/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9921\n","Epoch 150/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9921\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHCW6SRtJTDU","executionInfo":{"status":"ok","timestamp":1621778327275,"user_tz":-420,"elapsed":615,"user":{"displayName":"Farabie 19 Drive","photoUrl":"","userId":"03597380698045255649"}},"outputId":"ffa9f6f0-f1f8-4962-d4cc-2e3802a99396"},"source":["# evaluate the model\n","loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","print('Test Accuracy: %.3f' % acc)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Test Accuracy: 0.966\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXjGv--zJUnp","executionInfo":{"status":"ok","timestamp":1621778329904,"user_tz":-420,"elapsed":2,"user":{"displayName":"Farabie 19 Drive","photoUrl":"","userId":"03597380698045255649"}},"outputId":"c872c8ad-8aff-46f6-baeb-36cf9f25c400"},"source":["#Predict\n","row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n","yhat = model.predict([row])\n","print('Predicted: %.3f' % yhat)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Predicted: 0.989\n"],"name":"stdout"}]}]}